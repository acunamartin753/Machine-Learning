{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "or1xV3mE3xC0"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_05_seleccion_modelos-published.ipynb)\n",
        "\n",
        "# Selección de modelos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WAf_dRoe3xC1"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from IPython.display import display\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OESi81RV3xC1"
      },
      "source": [
        "## Cross validation\n",
        "\n",
        "Hasta ahora sólo habíamos visto (ver en el [notebook 03](https://github.com/aprendizaje-automatico-dc-uba-ar/material/blob/main/notebooks/notebook_03_arboles_de_decision_sklearn-published.ipynb)) que ibamos a dividir los datos en train y test.\n",
        "\n",
        "\n",
        "En esta semana vimos la opción de hacer validación cruzada. En esta oportunidad lo que haremos sera realizar una exploración de hiperparámetros para para árboles incorporando conceptos de la clase de esta semana.\n",
        "Vamos a experimentar usando k-fold (con k=10) para explorar distintos valores de configuración de `DecisionTreeClassifier` para seleccionar el hiperparámetro que nos parezca el mejor.\n",
        "Ensayaremos áltura máxima con valores `[None, 1, 2, 3, 5, 8, 13, 21]`.\n",
        "\n",
        "Nos interesará:\n",
        "- controlar el tiempo de entrenamiento\n",
        "- generar alguna métrica que elijamos para seleccionar la áltura máxima\n",
        "\n",
        "Con la mejor configuración obtenida entrenar un clasificador con todos los datos de desarrollo.\n",
        "    \n",
        "Evaluar el comportamiento con el set de evaluación\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Png77o1V3xC2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e34e3681-7c57-4364-b024-c221ab41bf2a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[ 0.74946762, -1.83875845,  2.31697643, ...,  0.38502105,\n",
              "          1.15910799,  0.36490854],\n",
              "        [ 1.36142303,  0.17739336, -1.06308644, ..., -0.00426734,\n",
              "         -1.63632588, -0.8335227 ],\n",
              "        [ 0.12238178,  1.03817562, -1.46411856, ...,  1.69000604,\n",
              "         -0.57898546,  0.34605186],\n",
              "        ...,\n",
              "        [ 0.77302083,  0.76832206, -0.36434009, ..., -0.05485574,\n",
              "         -0.51528272,  0.7993889 ],\n",
              "        [-0.54238642, -0.87839139,  0.68624112, ...,  0.20799802,\n",
              "          1.06110671, -0.34658297],\n",
              "        [-0.03135099,  0.93928815, -1.16413366, ...,  0.73422269,\n",
              "         -0.37504853, -0.59041732]]),\n",
              " array([1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
              "        1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0,\n",
              "        1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
              "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
              "        0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
              "        1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "import timeit\n",
        "import pandas as pd\n",
        "\n",
        "def cargar_datos():\n",
        "    df = pd.read_csv('https://github.com/aprendizaje-automatico-dc-uba-ar/material/raw/main/dataset/data_05/seleccion_modelos.csv')\n",
        "    X = df.drop(\"Y\", axis=1)\n",
        "    y = df.Y\n",
        "    return X.to_numpy(), y.to_numpy()\n",
        "\n",
        "X, y = cargar_datos()\n",
        "X,y"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dM6LfJn33xC3"
      },
      "source": [
        "Primero separaremos nuestro data set entre **desarrollo** y **evaluación** en un 10%. Para esto podemos usar `train_test_split`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fws9st-N3xC3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d94390c-bbc6-47d8-c0d2-85b4e093e810"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ],
      "source": [
        "# separamos entre dev y eval\n",
        "X_dev, X_eval, y_dev, y_eval = train_test_split(\n",
        "                    X,\n",
        "                    y,\n",
        "                    random_state=4,\n",
        "                    test_size=0.1)\n",
        "type(y_eval)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z56AhcDA3xC3"
      },
      "source": [
        "Por el momento dejaremos el set de evaluación de lado y nos manejaremos con el de desarrollo.\n",
        "\n",
        "Pasemos a experimentar los distinos `h_max` posibles.\n",
        "\n",
        "Usaremos estas dos funciones para entrenar un árbol y para usarlo para predecir respectivamente:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4kR_70h3xC3"
      },
      "outputs": [],
      "source": [
        "def train_tree(X_tr: np.ndarray, y_tr: np.ndarray, tree_params={}) -> DecisionTreeClassifier:\n",
        "    arbol = DecisionTreeClassifier(**tree_params)\n",
        "    arbol.fit(X_tr, y_tr)\n",
        "\n",
        "    return arbol\n",
        "\n",
        "def tree_predict(ab: DecisionTreeClassifier, X_test: np.ndarray) -> np.ndarray:\n",
        "    predictions = ab.predict(X_test)\n",
        "    return predictions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFJmEfxQ3xC4"
      },
      "source": [
        "Y definimos la métrica a usar. A modo de ejemplo figura accuracy.\n",
        "\n",
        "Cambiar la medida por una nueva vista en clase."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Tuple, Any"
      ],
      "metadata": {
        "id": "DhOP9k8W5IPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-TvJn1Tu3xC4"
      },
      "outputs": [],
      "source": [
        "def accuracy(y_predicted: np.ndarray, y_real: np.ndarray) -> float:\n",
        "    TP_TN = sum([y_i == y_j for (y_i, y_j) in zip(y_predicted, y_real)])\n",
        "    P_N = len(y_real)\n",
        "    return TP_TN /P_N\n",
        "### Nuevo\n",
        "\n",
        "def confusion_matrix(y_real: list, y_predicted: list, positive_label: Any, show: bool =False) -> Tuple[int, int, int, int]:\n",
        "    tp = sum([((y_i == y_j) and (y_i == positive_label)) for (y_i, y_j) in zip(y_predicted, y_real)])\n",
        "    tn = sum([((y_i == y_j) and (y_i != positive_label)) for (y_i, y_j) in zip(y_predicted, y_real)])\n",
        "    fp = sum([((y_i != y_j) and (y_i == positive_label)) for (y_i, y_j) in zip(y_predicted, y_real)])\n",
        "    fn = sum([((y_i != y_j) and (y_i != positive_label)) for (y_i, y_j) in zip(y_predicted, y_real)])\n",
        "\n",
        "    if show:\n",
        "        display(pd.DataFrame([[tp, fn], [fp, tn]], index=[\"real +\", \"real -\"], columns=[\"pred +\", \"pred -\"]))\n",
        "    return tp, tn, fp, fn\n",
        "\n",
        "\n",
        "def accuracy_score(tp: int, tn: int, fp: int, fn: int) -> float:\n",
        "    return (tp+tn)/(tp+tn+fp+fn)\n",
        "\n",
        "\n",
        "def precision_score(tp: int, tn: int, fp: int, fn: int) -> float:\n",
        "    if (tp+fp) != 0:\n",
        "      return tp/(tp+fp)\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "def recall_score(tp: int, tn: int, fp: int, fn: int) -> float:\n",
        "    if (tp+fn) != 0:\n",
        "      return tp/(tp+fn)\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "def f_beta_score(tp: int, tn: int, fp: int, fn: int, beta: float) -> float:\n",
        "    prec = precision_score(tp, tn, fp, fn)\n",
        "    recl = recall_score(tp, tn, fp, fn)\n",
        "    if ((beta**2)*prec+recl) != 0:\n",
        "      return (1+beta**2)*prec*recl/((beta**2)*prec+recl)\n",
        "    else:\n",
        "      return 0\n",
        "\n",
        "\n",
        "def f1_score(tp: int, tn: int, fp: int, fn: int) -> float:\n",
        "    return f_beta_score(tp, tn, fp, fn, beta=1)\n",
        "\n",
        "\n",
        "def metrica_seleccionada(y_predicted: np.ndarray, y_real: np.ndarray) -> float:\n",
        "    tp, tn, fp, fn = confusion_matrix(y_real=y_real, y_predicted=y_predicted, positive_label=1)\n",
        "    #return accuracy(y_predicted,y_real)\n",
        "    #return f1_score(tp,tn,fp,fn)\n",
        "    return f1_score(tp,tn,fp,fn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYQteJoF3xC5"
      },
      "source": [
        "Realización del experimento.\n",
        "\n",
        "Nota: se inicializa con una semilla para poder reproducir el resultado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKiBNy0P3xC5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "611f3b50-efe9-4f48-b79e-a4d6c40d449b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Órden obtenido según la métrica elegida\n",
            "\t1- h_max=1 con 0.833\n",
            "\t2- h_max=3 con 0.821\n",
            "\t3- h_max=2 con 0.809\n",
            "\t4- h_max=5 con 0.808\n",
            "\t5- h_max=8 con 0.777\n",
            "\t6- h_max=None con 0.755\n",
            "\t7- h_max=21 con 0.738\n",
            "\t8- h_max=13 con 0.727\n"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "\n",
        "np.random.seed(44)\n",
        "for h_max in [None, 1, 2, 3, 5, 8, 13, 21]:\n",
        "    kf = KFold(n_splits=10)\n",
        "    y_pred = np.empty(y_dev.shape)\n",
        "    y_pred.fill(np.nan)\n",
        "\n",
        "    # generamos para cada fold una predicción\n",
        "    for train_index, test_index in kf.split(X_dev):\n",
        "\n",
        "        #saco el fold que no uso para entrenar\n",
        "        kf_X_train, kf_X_test = X_dev[train_index], X_dev[test_index]\n",
        "        kf_y_train, kf_y_test = y_dev[train_index], y_dev[test_index]\n",
        "\n",
        "        current_tree = train_tree(kf_X_train, kf_y_train,\n",
        "                                    tree_params={\"max_depth\":h_max})\n",
        "        predictions = tree_predict(current_tree, kf_X_test)\n",
        "        y_pred[test_index] = predictions\n",
        "\n",
        "    current_score = metrica_seleccionada(y_pred, y_dev)\n",
        "\n",
        "    results.append((h_max,current_score))\n",
        "\n",
        "\n",
        "# Ordenamos los resultados (puede ser que convenga del derecho o del reves)\n",
        "r = sorted(results, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "print(\"Órden obtenido según la métrica elegida\")\n",
        "for idx, (h, sc) in enumerate(r):\n",
        "    print(f\"\\t{idx+1}- h_max={h} con {sc:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZEN-ab63xC5"
      },
      "source": [
        "Con los resultados obtenidos podemos elegir la `h_max` que nos parezca mejor. Con eso vamos a reentrenar el modelo con todos los datos.\n",
        "\n",
        "¿Qué teníamos que tener en cuenta en estos casos?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NOCMGZuO3xC6"
      },
      "outputs": [],
      "source": [
        "# elegimos\n",
        "h_max = 1 # COMPLETAR\n",
        "selection_score = 0.833 # COMPLETAR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CR-TysBM3xC6"
      },
      "outputs": [],
      "source": [
        "assert selection_score is not None, \"Completar la celda anterior para continuar\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ltj8Gb_f3xC6"
      },
      "source": [
        "Con el mejor parámetro entrenamos un nuevo clasificador:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syyqwzqT3xC6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "393f4001-30a9-422a-f2f2-d7cb8265e366"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Construimos nuestro clasificador con parámetro 'max_depth'=1.Para seleccionarlo el score que habíamos obtenido era 0.833\n"
          ]
        }
      ],
      "source": [
        "print(f\"Construimos nuestro clasificador con parámetro 'max_depth'={h_max}.\"\n",
        "     + f\"Para seleccionarlo el score que habíamos obtenido era {selection_score:.3f}\")\n",
        "\n",
        "best_tree = train_tree(X_dev, y_dev,\n",
        "                            tree_params={\"max_depth\":h_max})\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMxljon73xC6"
      },
      "source": [
        "Podemos evaluar este árbol en train."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1u0vJPH43xC7"
      },
      "outputs": [],
      "source": [
        "y_pred = tree_predict(best_tree, X_dev)\n",
        "best_tree_score = metrica_seleccionada(y_pred, y_dev)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9i5W_bn3xC8"
      },
      "source": [
        "¿Qué nos están diciendo estos dos scores?¿Para qué nos sirven?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_tree_score"
      ],
      "metadata": {
        "id": "4J0rxAoG-XKJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "681cd443-085a-43fd-e561-901c739bc5c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8631578947368421"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uEC7Lrlg3xC8"
      },
      "source": [
        "Por única vez vemos como funciona nuestro entrenamiento en los datos de **evaluación** que no habíamos mirado."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UpPDRnaF3xC8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18d183b9-7aad-47f2-f800-7e89f8c8c39b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Con el árbol entrenado con el parámetro seleccionado tenemos en eval un score de 0.600\n"
          ]
        }
      ],
      "source": [
        "y_pred_eval = tree_predict(best_tree, X_eval)\n",
        "best_tree_score_eval = metrica_seleccionada(y_pred_eval, y_eval)\n",
        "\n",
        "print(f\"Con el árbol entrenado con el parámetro seleccionado tenemos en eval un score de {best_tree_score_eval:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL = best_tree_score_eval\n",
        "CV = best_tree_score\n",
        "print((((EVAL - CV) / CV ) * 100))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l6ZcZ3CN7iNa",
        "outputId": "6725a185-dedc-4ed0-f63e-603b29809bd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-30.487804878048784\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EVAL"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XX2Zxx-n71vx",
        "outputId": "3ab00d9b-a3ae-45e9-99fa-8d30d568f45e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q-G07G353xC8"
      },
      "source": [
        "## Opcionales\n",
        "\n",
        "1. Simular qué hubiese ocurrido si hubieramos elegido un K distinto. ¿La diferencia entre el score en *dev* y el score en *eval* cambia significativamente?\n",
        "2. Repetir el mismo ejercicio de elegir la mejor combinación de parametros pero esta vez establecer una grilla donde se exploren al menos dos hiperparámetros que no sean la altura máxima. Revisar la documentación de `DecisionTreeClassifier`, por ejemplo pueden elegir la **medida de impureza** y el **mínimo de muestas necesario para realizar un split**. Definir los rangos necesarios para explorar más de un valor de cada hiperparámetro considerado. ¿Este modelo fue mejor que el obtenido en el punto anterior?\n",
        "\n",
        "**Importante**: en este punto nos tomamos la licencia de usar nuevamente el conjunto de evaluación. El re-uso de el conjunto de evaluación sólo lo permitimos en este caso por motivos pedagócios. Pero **NO DEBE** suceder en la práctica.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ehyHBlueh2G_"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}